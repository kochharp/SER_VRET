{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-08-11T15:19:40.975418Z",
     "iopub.status.busy": "2025-08-11T15:19:40.975097Z",
     "iopub.status.idle": "2025-08-11T15:19:40.981146Z",
     "shell.execute_reply": "2025-08-11T15:19:40.980213Z",
     "shell.execute_reply.started": "2025-08-11T15:19:40.975387Z"
    },
    "id": "EWDS0ipyQxQB"
   },
   "outputs": [],
   "source": [
    "# Kaggle default setup code\n",
    "\n",
    "# # This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# # For example, here's several helpful packages to load\n",
    "\n",
    "# import numpy as np # linear algebra\n",
    "# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# # Input data files are available in the read-only \"../input/\" directory\n",
    "# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "# import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
    "# # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T16:53:41.421699Z",
     "iopub.status.busy": "2025-08-11T16:53:41.421502Z",
     "iopub.status.idle": "2025-08-11T16:54:26.956416Z",
     "shell.execute_reply": "2025-08-11T16:54:26.955745Z",
     "shell.execute_reply.started": "2025-08-11T16:53:41.421682Z"
    },
    "id": "_64VmIG4QxQC",
    "outputId": "67a588dc-87f2-43bf-d714-901206e0a93f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-11 16:54:04.759392: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1754931245.133119      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1754931245.236460      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import os, random, math, json, warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import torchaudio\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "from transformers import (\n",
    "    Wav2Vec2Processor,\n",
    "    Wav2Vec2ForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    ")\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "DATA_ROOT = \"/kaggle/input/nor-smart-speech\"\n",
    "SR = 16000\n",
    "MAX_SEC = 4\n",
    "MAX_LEN = SR*MAX_SEC\n",
    "\n",
    "emotion_map = {\n",
    "    'angry':0, 'disgust':1, 'fear':2, 'happy':3, 'neutral':4, 'sad':5\n",
    "}\n",
    "inv_map = {v:k for k,v in emotion_map.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T16:54:47.433943Z",
     "iopub.status.busy": "2025-08-11T16:54:47.433675Z",
     "iopub.status.idle": "2025-08-11T16:55:14.798590Z",
     "shell.execute_reply": "2025-08-11T16:55:14.798007Z",
     "shell.execute_reply.started": "2025-08-11T16:54:47.433922Z"
    },
    "id": "cW1ZW0CaQxQD",
    "outputId": "efa7d6ff-c957-4a89-bd30-5a2a20e02650"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total files found: 19487\n",
      "label\n",
      "angry      3376\n",
      "disgust    2822\n",
      "fear       2901\n",
      "happy      3681\n",
      "neutral    3270\n",
      "sad        3437\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/kaggle/input/nor-smart-speech/disgust/03-02-0...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/kaggle/input/nor-smart-speech/angry/03-01-05-...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/kaggle/input/nor-smart-speech/happy/03-01-03-...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/kaggle/input/nor-smart-speech/sad/1040_IWL_SA...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/kaggle/input/nor-smart-speech/happy/1049_ITH_...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path  label\n",
       "0  /kaggle/input/nor-smart-speech/disgust/03-02-0...      1\n",
       "1  /kaggle/input/nor-smart-speech/angry/03-01-05-...      0\n",
       "2  /kaggle/input/nor-smart-speech/happy/03-01-03-...      3\n",
       "3  /kaggle/input/nor-smart-speech/sad/1040_IWL_SA...      5\n",
       "4  /kaggle/input/nor-smart-speech/happy/1049_ITH_...      3"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_paths, labels = [], []\n",
    "seen = set()\n",
    "\n",
    "for root, _, files in os.walk(DATA_ROOT):\n",
    "    for f in files:\n",
    "        if not f.lower().endswith(\".wav\"):\n",
    "            continue\n",
    "        fname = f.lower()\n",
    "        if fname in seen:\n",
    "            continue\n",
    "\n",
    "        label_folder = os.path.basename(root).lower()\n",
    "        if label_folder in emotion_map:\n",
    "            seen.add(fname)\n",
    "            audio_paths.append(os.path.join(root, f))\n",
    "            labels.append(emotion_map[label_folder])\n",
    "\n",
    "df = pd.DataFrame({\"path\": audio_paths, \"label\": labels})\n",
    "df = df.sample(frac=1, random_state=SEED).reset_index(drop=True)\n",
    "\n",
    "print(\"Total files found:\", len(df))\n",
    "print(df[\"label\"].map(inv_map).value_counts().sort_index())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T16:55:48.858161Z",
     "iopub.status.busy": "2025-08-11T16:55:48.857459Z",
     "iopub.status.idle": "2025-08-11T16:55:48.880801Z",
     "shell.execute_reply": "2025-08-11T16:55:48.880008Z",
     "shell.execute_reply.started": "2025-08-11T16:55:48.858138Z"
    },
    "id": "Bug6irdKQxQD",
    "outputId": "f9f0f742-3cdc-43ed-aa25-40e6c148f207"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Val/Test sizes: 15589 1949 1949\n",
      "Train dist:\n",
      " label\n",
      "angry      2701\n",
      "disgust    2257\n",
      "fear       2321\n",
      "happy      2945\n",
      "neutral    2616\n",
      "sad        2749\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_df, temp_df = train_test_split(df, test_size=0.20, stratify=df[\"label\"], random_state=SEED)\n",
    "val_df, test_df   = train_test_split(temp_df, test_size=0.50, stratify=temp_df[\"label\"], random_state=SEED)\n",
    "\n",
    "print(\"Train/Val/Test sizes:\", len(train_df), len(val_df), len(test_df))\n",
    "print(\"Train dist:\\n\", train_df[\"label\"].map(inv_map).value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T17:10:37.451751Z",
     "iopub.status.busy": "2025-08-11T17:10:37.451443Z",
     "iopub.status.idle": "2025-08-11T17:10:37.469569Z",
     "shell.execute_reply": "2025-08-11T17:10:37.468778Z",
     "shell.execute_reply.started": "2025-08-11T17:10:37.451728Z"
    },
    "id": "8I2rNYDJQxQD"
   },
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Robust audio augmentation\n",
    "# ---------------------------\n",
    "import numpy as np\n",
    "import random\n",
    "import librosa\n",
    "\n",
    "SR       = 16000\n",
    "MAX_SEC  = 4\n",
    "MAX_LEN  = SR * MAX_SEC\n",
    "\n",
    "def _pad_or_trim(y, target_len=MAX_LEN):\n",
    "    if y is None or len(y) == 0:\n",
    "        y = np.zeros(target_len, dtype=np.float32)\n",
    "    if len(y) >= target_len:\n",
    "        return y[:target_len].astype(np.float32)\n",
    "    return np.pad(y.astype(np.float32), (0, target_len - len(y)))\n",
    "\n",
    "def _sanitize(y):\n",
    "    if not np.isfinite(y).all():\n",
    "        y = np.nan_to_num(y, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    # soft clip to [-1, 1]\n",
    "    y = np.clip(y, -1.0, 1.0)\n",
    "    return y.astype(np.float32)\n",
    "\n",
    "def add_gaussian_noise(y, snr_db=20.0):\n",
    "    try:\n",
    "        rms = np.sqrt(np.mean(y**2) + 1e-9)\n",
    "        snr = 10**(snr_db/20.0)\n",
    "        noise_rms = rms / max(snr, 1e-6)\n",
    "        noise = np.random.normal(0.0, noise_rms, size=y.shape).astype(np.float32)\n",
    "        y_out = y + noise\n",
    "        return _sanitize(y_out)\n",
    "    except Exception:\n",
    "        return y\n",
    "\n",
    "def pitch_shift_aug(y, sr=SR, n_steps=0.0):\n",
    "    try:\n",
    "        y_out = librosa.effects.pitch_shift(y, sr=sr, n_steps=n_steps)\n",
    "        return _sanitize(_pad_or_trim(y_out))\n",
    "    except Exception:\n",
    "        return y\n",
    "\n",
    "def time_stretch_aug(y, rate=1.0):\n",
    "    try:\n",
    "        rate = float(rate)\n",
    "        rate = np.clip(rate, 0.8, 1.25)  # safety bounds\n",
    "        y_out = librosa.effects.time_stretch(y, rate)\n",
    "        return _sanitize(_pad_or_trim(y_out))\n",
    "    except Exception:\n",
    "        return y\n",
    "\n",
    "def time_shift_aug(y, max_frac=0.1):\n",
    "    try:\n",
    "        max_frac = float(np.clip(max_frac, 0.0, 0.49))\n",
    "        shift = int(random.uniform(-max_frac, max_frac) * len(y))\n",
    "        y_out = np.roll(y, shift)\n",
    "        return _sanitize(y_out)\n",
    "    except Exception:\n",
    "        return y\n",
    "\n",
    "def random_gain_aug(y, low=0.9, high=1.1):\n",
    "    try:\n",
    "        g = float(random.uniform(low, high))\n",
    "        return _sanitize(y * g)\n",
    "    except Exception:\n",
    "        return y\n",
    "\n",
    "def bandpass_filt_aug(y, sr=SR, low=100.0, high=7000.0):\n",
    "    \"\"\"Simple STFT mask to mimic bandpass (cheap & stable).\"\"\"\n",
    "    try:\n",
    "        S = librosa.stft(y, n_fft=512, hop_length=160, win_length=400)\n",
    "        freqs = librosa.fft_frequencies(sr=sr, n_fft=512)\n",
    "        mask = (freqs >= low) & (freqs <= high)\n",
    "        S[~mask, :] = 0\n",
    "        y_out = librosa.istft(S, hop_length=160, win_length=400, length=len(y))\n",
    "        return _sanitize(y_out)\n",
    "    except Exception:\n",
    "        return y\n",
    "\n",
    "def augment_waveform(\n",
    "    y,\n",
    "    sr=SR,\n",
    "    probs=dict(noise=0.5, pitch=0.3, stretch=0.3, shift=0.4, gain=0.5, bandpass=0.2),\n",
    "    ranges=dict(snr=(15,25), pitch=(-1.5,1.5), stretch=(0.9,1.1), shift=0.08, gain=(0.9,1.1), bp=(100,7000))\n",
    "):\n",
    "    \"\"\"\n",
    "    Robust, probabilistic augmentations. Always returns a valid, length-exact waveform.\n",
    "    \"\"\"\n",
    "    y = _pad_or_trim(y)\n",
    "    y = _sanitize(y)\n",
    "\n",
    "    # noise\n",
    "    if random.random() < probs.get(\"noise\", 0):\n",
    "        snr_lo, snr_hi = ranges[\"snr\"]\n",
    "        y = add_gaussian_noise(y, snr_db=random.uniform(snr_lo, snr_hi))\n",
    "\n",
    "    # pitch\n",
    "    if random.random() < probs.get(\"pitch\", 0):\n",
    "        p_lo, p_hi = ranges[\"pitch\"]\n",
    "        y = pitch_shift_aug(y, sr=sr, n_steps=random.uniform(p_lo, p_hi))\n",
    "\n",
    "    # stretch\n",
    "    if random.random() < probs.get(\"stretch\", 0):\n",
    "        s_lo, s_hi = ranges[\"stretch\"]\n",
    "        y = time_stretch_aug(y, rate=random.uniform(s_lo, s_hi))\n",
    "\n",
    "    # shift\n",
    "    if random.random() < probs.get(\"shift\", 0):\n",
    "        y = time_shift_aug(y, max_frac=ranges[\"shift\"])\n",
    "\n",
    "    # gain\n",
    "    if random.random() < probs.get(\"gain\", 0):\n",
    "        g_lo, g_hi = ranges[\"gain\"]\n",
    "        y = random_gain_aug(y, low=g_lo, high=g_hi)\n",
    "\n",
    "    # bandpass\n",
    "    if random.random() < probs.get(\"bandpass\", 0):\n",
    "        low, high = ranges[\"bp\"]\n",
    "        y = bandpass_filt_aug(y, sr=sr, low=low, high=high)\n",
    "\n",
    "    # final safety\n",
    "    return _pad_or_trim(_sanitize(y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T17:11:05.498651Z",
     "iopub.status.busy": "2025-08-11T17:11:05.497734Z",
     "iopub.status.idle": "2025-08-11T17:11:05.509136Z",
     "shell.execute_reply": "2025-08-11T17:11:05.508194Z",
     "shell.execute_reply.started": "2025-08-11T17:11:05.498615Z"
    },
    "id": "_FoNnUjPQxQE"
   },
   "outputs": [],
   "source": [
    "class SERDataset(Dataset):\n",
    "    def __init__(self, df, processor, is_train=False, max_len=MAX_LEN, sr=SR):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.processor = processor\n",
    "        self.is_train = is_train\n",
    "        self.max_len = max_len\n",
    "        self.sr = sr\n",
    "\n",
    "    def __len__(self): return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        p = self.df.loc[idx, \"path\"]\n",
    "        y, _ = librosa.load(p, sr=self.sr, mono=True)\n",
    "\n",
    "        # pad/trim up front for stability\n",
    "        if len(y) >= self.max_len:\n",
    "            y = y[:self.max_len]\n",
    "        else:\n",
    "            y = np.pad(y, (0, self.max_len - len(y)))\n",
    "\n",
    "        if self.is_train:\n",
    "            y = augment_waveform(y, sr=self.sr)  # robust version\n",
    "\n",
    "        inputs = self.processor(\n",
    "            y, sampling_rate=self.sr, return_tensors=\"pt\", padding=True, truncation=False\n",
    "        )\n",
    "        label = int(self.df.loc[idx, \"label\"])\n",
    "        return {\n",
    "            \"input_values\": inputs.input_values.squeeze(0),\n",
    "            \"labels\": torch.tensor(label, dtype=torch.long),\n",
    "        }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T17:11:05.882755Z",
     "iopub.status.busy": "2025-08-11T17:11:05.882460Z",
     "iopub.status.idle": "2025-08-11T17:11:06.235891Z",
     "shell.execute_reply": "2025-08-11T17:11:06.235012Z",
     "shell.execute_reply.started": "2025-08-11T17:11:05.882732Z"
    },
    "id": "o20yzhUsQxQE",
    "outputId": "6b366691-bc11-4624-a52e-9c54ae31731b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2ForSequenceClassification were not initialized from the model checkpoint at /kaggle/input/ravdess-wav2vec2 and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([5]) in the checkpoint and torch.Size([6]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([5, 256]) in the checkpoint and torch.Size([6, 256]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "MODEL_PATH = \"/kaggle/input/ravdess-wav2vec2\"\n",
    "\n",
    "processor = Wav2Vec2Processor.from_pretrained(MODEL_PATH)\n",
    "\n",
    "# 6 labels in NOR dataset\n",
    "model = Wav2Vec2ForSequenceClassification.from_pretrained(\n",
    "    MODEL_PATH,\n",
    "    num_labels=6,\n",
    "    problem_type=\"single_label_classification\",\n",
    "    ignore_mismatched_sizes=True\n",
    ").to(DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T17:11:25.209324Z",
     "iopub.status.busy": "2025-08-11T17:11:25.209019Z",
     "iopub.status.idle": "2025-08-11T17:11:25.214980Z",
     "shell.execute_reply": "2025-08-11T17:11:25.214119Z",
     "shell.execute_reply.started": "2025-08-11T17:11:25.209304Z"
    },
    "id": "31JVXlH7QxQE"
   },
   "outputs": [],
   "source": [
    "train_ds = SERDataset(train_df, processor, is_train=True)\n",
    "val_ds   = SERDataset(val_df,   processor, is_train=False)\n",
    "test_ds  = SERDataset(test_df,  processor, is_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T17:15:32.557141Z",
     "iopub.status.busy": "2025-08-11T17:15:32.556551Z",
     "iopub.status.idle": "2025-08-11T17:15:32.566070Z",
     "shell.execute_reply": "2025-08-11T17:15:32.565360Z",
     "shell.execute_reply.started": "2025-08-11T17:15:32.557116Z"
    },
    "id": "dIcmiAJxQxQE",
    "outputId": "1ce3d4b5-b0f7-4437-ed97-d1af53f61204"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: {'angry': 0.9534974098205566, 'disgust': 1.1410706043243408, 'fear': 1.1096065044403076, 'happy': 0.8744979500770569, 'neutral': 0.9844788312911987, 'sad': 0.936848521232605}\n"
     ]
    }
   ],
   "source": [
    "# compute weights = 1 / freq\n",
    "counts = train_df[\"label\"].value_counts().sort_index().values.astype(np.float32)\n",
    "class_weights = (1.0 / (counts + 1e-6))\n",
    "class_weights = class_weights / class_weights.sum() * len(counts)\n",
    "class_weights_t = torch.tensor(class_weights, dtype=torch.float, device=DEVICE)\n",
    "print(\"Class weights:\", {inv_map[i]: float(w) for i,w in enumerate(class_weights)})\n",
    "\n",
    "class WeightedTrainer(Trainer):\n",
    "    # accept **kwargs to be future-proof\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "\n",
    "        labels = inputs[\"labels\"]\n",
    "        if labels.dtype != torch.long:\n",
    "            labels = labels.long()\n",
    "\n",
    "\n",
    "        outputs = model(**{k: v for k, v in inputs.items() if k != \"labels\"})\n",
    "        logits = outputs.get(\"logits\")\n",
    "\n",
    "        loss_fct = nn.CrossEntropyLoss(weight=class_weights_t.to(logits.device))\n",
    "        loss = loss_fct(logits, labels.to(logits.device))\n",
    "\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T17:15:33.848939Z",
     "iopub.status.busy": "2025-08-11T17:15:33.848654Z",
     "iopub.status.idle": "2025-08-11T17:15:33.853604Z",
     "shell.execute_reply": "2025-08-11T17:15:33.852976Z",
     "shell.execute_reply.started": "2025-08-11T17:15:33.848916Z"
    },
    "id": "9bkaduc4QxQF"
   },
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=1)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(labels, preds, average=\"weighted\", zero_division=0)\n",
    "    return {\"accuracy\": acc, \"precision\": prec, \"recall\": rec, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T17:15:36.490989Z",
     "iopub.status.busy": "2025-08-11T17:15:36.490344Z",
     "iopub.status.idle": "2025-08-11T19:44:54.702598Z",
     "shell.execute_reply": "2025-08-11T19:44:54.701525Z",
     "shell.execute_reply.started": "2025-08-11T17:15:36.490945Z"
    },
    "id": "lArije2hQxQF",
    "outputId": "17fd19b6-ae3e-474f-d9d5-396c78c675ba"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9750' max='9750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9750/9750 2:28:43, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.003000</td>\n",
       "      <td>0.860664</td>\n",
       "      <td>0.720883</td>\n",
       "      <td>0.730815</td>\n",
       "      <td>0.720883</td>\n",
       "      <td>0.722325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.840300</td>\n",
       "      <td>0.730775</td>\n",
       "      <td>0.751154</td>\n",
       "      <td>0.764732</td>\n",
       "      <td>0.751154</td>\n",
       "      <td>0.750914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.693400</td>\n",
       "      <td>0.641532</td>\n",
       "      <td>0.786557</td>\n",
       "      <td>0.790927</td>\n",
       "      <td>0.786557</td>\n",
       "      <td>0.786050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.620600</td>\n",
       "      <td>0.601095</td>\n",
       "      <td>0.795280</td>\n",
       "      <td>0.799014</td>\n",
       "      <td>0.795280</td>\n",
       "      <td>0.795190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.532400</td>\n",
       "      <td>0.556260</td>\n",
       "      <td>0.813238</td>\n",
       "      <td>0.814853</td>\n",
       "      <td>0.813238</td>\n",
       "      <td>0.812697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.491700</td>\n",
       "      <td>0.637334</td>\n",
       "      <td>0.793740</td>\n",
       "      <td>0.799951</td>\n",
       "      <td>0.793740</td>\n",
       "      <td>0.793972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.419200</td>\n",
       "      <td>0.594414</td>\n",
       "      <td>0.816316</td>\n",
       "      <td>0.818065</td>\n",
       "      <td>0.816316</td>\n",
       "      <td>0.816366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.385000</td>\n",
       "      <td>0.598723</td>\n",
       "      <td>0.806567</td>\n",
       "      <td>0.810481</td>\n",
       "      <td>0.806567</td>\n",
       "      <td>0.806573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.312900</td>\n",
       "      <td>0.591484</td>\n",
       "      <td>0.816829</td>\n",
       "      <td>0.817057</td>\n",
       "      <td>0.816829</td>\n",
       "      <td>0.816687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.271300</td>\n",
       "      <td>0.599801</td>\n",
       "      <td>0.821960</td>\n",
       "      <td>0.822787</td>\n",
       "      <td>0.821960</td>\n",
       "      <td>0.822106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='244' max='122' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [122/122 01:47]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: {'eval_loss': 0.5998007655143738, 'eval_accuracy': 0.8219599794766547, 'eval_precision': 0.822787228814219, 'eval_recall': 0.8219599794766547, 'eval_f1': 0.8221063763739254, 'eval_runtime': 28.6098, 'eval_samples_per_second': 68.124, 'eval_steps_per_second': 4.264, 'epoch': 10.0}\n"
     ]
    }
   ],
   "source": [
    "args = TrainingArguments(\n",
    "    output_dir=\"./nor-wav2vec2-results\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=100,\n",
    "    report_to=[],\n",
    "    fp16=torch.cuda.is_available(),\n",
    ")\n",
    "\n",
    "trainer = WeightedTrainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=val_ds,\n",
    "    tokenizer=processor,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "val_metrics = trainer.evaluate()\n",
    "print(\"Validation:\", val_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T19:45:14.676191Z",
     "iopub.status.busy": "2025-08-11T19:45:14.675205Z",
     "iopub.status.idle": "2025-08-11T19:46:14.648306Z",
     "shell.execute_reply": "2025-08-11T19:46:14.647395Z",
     "shell.execute_reply.started": "2025-08-11T19:45:14.676162Z"
    },
    "id": "WV0Y4Eo3QxQF",
    "outputId": "afad3550-a32c-4775-84e4-2cab72a67b4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: {'eval_loss': 0.6594431400299072, 'eval_accuracy': 0.8086198050282196, 'eval_precision': 0.8110265307552449, 'eval_recall': 0.8086198050282196, 'eval_f1': 0.8090447258311045, 'eval_runtime': 59.3287, 'eval_samples_per_second': 32.851, 'eval_steps_per_second': 2.056, 'epoch': 10.0}\n",
      "Saved to ./nor-pretrained-wav2vec2\n"
     ]
    }
   ],
   "source": [
    "test_metrics = trainer.evaluate(test_ds)\n",
    "print(\"Test:\", test_metrics)\n",
    "\n",
    "# Saving to reuse\n",
    "save_dir = \"./nor-pretrained-wav2vec2\"\n",
    "model.save_pretrained(save_dir)\n",
    "processor.save_pretrained(save_dir)\n",
    "print(\"Saved to\", save_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T19:46:35.442485Z",
     "iopub.status.busy": "2025-08-11T19:46:35.441729Z",
     "iopub.status.idle": "2025-08-11T19:46:35.617151Z",
     "shell.execute_reply": "2025-08-11T19:46:35.616447Z",
     "shell.execute_reply.started": "2025-08-11T19:46:35.442459Z"
    },
    "id": "eDBkMA7VQxQF",
    "outputId": "e699d198-acb0-4060-8aa0-21664a19b7a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred: fear | True: fear\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "idx = random.randrange(len(test_ds))\n",
    "sample = test_ds[idx]\n",
    "with torch.no_grad():\n",
    "    logits = model(sample[\"input_values\"].unsqueeze(0).to(DEVICE)).logits\n",
    "pred = logits.argmax(dim=-1).item()\n",
    "print(\"Pred:\", inv_map[pred], \"| True:\", inv_map[int(sample[\"labels\"])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T19:49:20.163552Z",
     "iopub.status.busy": "2025-08-11T19:49:20.162902Z",
     "iopub.status.idle": "2025-08-11T19:49:20.835770Z",
     "shell.execute_reply": "2025-08-11T19:49:20.835007Z",
     "shell.execute_reply.started": "2025-08-11T19:49:20.163528Z"
    },
    "id": "eajnhILwQxQF",
    "outputId": "0ce64f20-a540-43e6-da3d-032911843c43"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Wav2Vec2ForSequenceClassification, Wav2Vec2Processor\n",
    "import shutil\n",
    "\n",
    "model.save_pretrained(\"wav2vec2_nor_model\")\n",
    "processor.save_pretrained(\"wav2vec2_nor_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T19:49:55.458636Z",
     "iopub.status.busy": "2025-08-11T19:49:55.458233Z",
     "iopub.status.idle": "2025-08-11T19:50:17.609673Z",
     "shell.execute_reply": "2025-08-11T19:50:17.608768Z",
     "shell.execute_reply.started": "2025-08-11T19:49:55.458605Z"
    },
    "id": "n2tbqRLuQxQG",
    "outputId": "6a498833-a811-491e-a421-a403387863dd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/kaggle/working/wav2vec2_nor_model.zip'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saving zip file of the model\n",
    "\n",
    "shutil.make_archive(\"wav2vec2_nor_model\", 'zip', \"wav2vec2_nor_model\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 2716311,
     "sourceId": 4689722,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8050853,
     "sourceId": 12736549,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
